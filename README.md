# Stochastic-
Stochastic Optimisation
# **Projet optimisation stochastique : Fonction de Rosenbrock**

# I- Introduction

L'optimisation stochastique, une branche dynamique de l'optimisation, s'est avérée importante pour résoudre des problèmes complexes et non déterministes, où les paramètres évoluent de manière incertaine ou aléatoire.

L'étude de fonctions objets dans ce contexte permet de développer des algorithmes capables de trouver des solutions robustes et performantes.

Dans le cadre de ce projet, nous nous penchons sur la fonction de Rosenbrock, une fonction d'optimisation classique et emblématique, afin d'explorer les défis qu'elle pose et de comparer les approches stochastiques pour son optimisation.


## Qu'est ce que la fonction de Rosenbrock ?

La fonction de Rosenbrock, également désignée sous les termes de "vallée de Rosenbrock" ou "fonction de Rosenbrock's valley", est fréquemment utilisée comme référence pour évaluer les performances d'algorithmes d'optimisation. Mathématiquement définie comme suit :
  
  
  **f(x, y) = (a - x)² + b * (y - x²)²**

où a et b sont des constantes positives, la fonction de Rosenbrock se caractérise par une forme allongée et étroite, créant ainsi une vallée profonde et étroite. La quête du minimum global de cette fonction est un défi en raison de l'existence d'une trajectoire plate prolongée conduisant au minimum global.
